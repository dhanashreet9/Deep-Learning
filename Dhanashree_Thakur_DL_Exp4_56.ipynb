{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name - Dhanashree Thakur\n",
        "\n",
        "Roll No - 56\n",
        "\n",
        "Branch - CSE(DS)\n",
        "\n",
        "Experiment No.4"
      ],
      "metadata": {
        "id": "JMd69fDVnxY1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7pZM-NwOm0zH"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    s = sigmoid(x)\n",
        "    return s * (1 - s)\n",
        "\n",
        "class DNN:\n",
        "    def __init__(self, input_size, hidden1_size, hidden2_size, output_size, lr=0.01):\n",
        "        self.lr = lr\n",
        "        self.W1, self.b1 = np.random.randn(input_size, hidden1_size), np.zeros((1, hidden1_size))\n",
        "        self.W2, self.b2 = np.random.randn(hidden1_size, hidden2_size), np.zeros((1, hidden2_size))\n",
        "        self.W3, self.b3 = np.random.randn(hidden2_size, output_size), np.zeros((1, output_size))\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.A1 = sigmoid(X @ self.W1 + self.b1)\n",
        "        self.A2 = sigmoid(self.A1 @ self.W2 + self.b2)\n",
        "        self.A3 = sigmoid(self.A2 @ self.W3 + self.b3)\n",
        "        return self.A3\n",
        "\n",
        "    def backward(self, X, y):\n",
        "        m = y.size\n",
        "        dA3 = (self.A3 - y) * sigmoid_derivative(self.A3)\n",
        "        dW3, db3 = self.A2.T @ dA3 / m, np.sum(dA3, axis=0, keepdims=True) / m\n",
        "        dA2 = dA3 @ self.W3.T * sigmoid_derivative(self.A2)\n",
        "        dW2, db2 = self.A1.T @ dA2 / m, np.sum(dA2, axis=0, keepdims=True) / m\n",
        "        dA1 = dA2 @ self.W2.T * sigmoid_derivative(self.A1)\n",
        "        dW1, db1 = X.T @ dA1 / m, np.sum(dA1, axis=0, keepdims=True) / m\n",
        "\n",
        "        self.W3 -= self.lr * dW3\n",
        "        self.b3 -= self.lr * db3\n",
        "        self.W2 -= self.lr * dW2\n",
        "        self.b2 -= self.lr * db2\n",
        "        self.W1 -= self.lr * dW1\n",
        "        self.b1 -= self.lr * db1\n",
        "\n",
        "    def train(self, X, y, epochs=1000):\n",
        "        for epoch in range(epochs):\n",
        "            self.forward(X)\n",
        "            self.backward(X, y)\n",
        "            if epoch % 100 == 0:\n",
        "                loss = np.mean((self.A3 - y) ** 2)\n",
        "                print(f'Epoch {epoch}, Loss: {loss:.6f}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(0)\n",
        "    X = np.random.rand(100, 2)\n",
        "    y = (np.sin(X[:, 0]) + np.cos(X[:, 1])).reshape(-1, 1)\n",
        "    dnn = DNN(2, 4, 4, 1, 0.01)\n",
        "    dnn.train(X, y, 1000)\n",
        "    print(\"Predictions:\", dnn.forward(X)[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxJcizJ8m9RF",
        "outputId": "1472f942-5a41-4fd4-f8c4-2b6c40220935"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.517631\n",
            "Epoch 100, Loss: 1.282046\n",
            "Epoch 200, Loss: 1.037683\n",
            "Epoch 300, Loss: 0.832841\n",
            "Epoch 400, Loss: 0.679547\n",
            "Epoch 500, Loss: 0.569277\n",
            "Epoch 600, Loss: 0.489931\n",
            "Epoch 700, Loss: 0.431840\n",
            "Epoch 800, Loss: 0.388333\n",
            "Epoch 900, Loss: 0.354991\n",
            "Predictions: [[0.82996932]\n",
            " [0.82730556]\n",
            " [0.83010033]\n",
            " [0.83270848]\n",
            " [0.82130605]]\n"
          ]
        }
      ]
    }
  ]
}